{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Load dataset from MovieLens 100k\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
        "df = pd.read_csv(url, sep='\\t', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
        "\n",
        "\n",
        "df.drop('timestamp', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "df['userId'] = df['userId'].astype('category')\n",
        "df['movieId'] = df['movieId'].astype('category')\n",
        "\n",
        "user_id_map = dict(enumerate(df['userId'].cat.categories))\n",
        "movie_id_map = dict(enumerate(df['movieId'].cat.categories))\n",
        "\n",
        "df['user_index'] = df['userId'].cat.codes\n",
        "df['movie_index'] = df['movieId'].cat.codes\n",
        "\n",
        "n_users = df['user_index'].nunique()\n",
        "n_movies = df['movie_index'].nunique()\n",
        "\n",
        "# Step 2: Train-Test Split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_data = train_df[['user_index', 'movie_index', 'rating']].values\n",
        "test_data = test_df[['user_index', 'movie_index', 'rating']].values\n",
        "\n",
        "\n",
        "K = 10  # latent factors\n",
        "P = np.random.normal(scale=1./K, size=(n_users, K))\n",
        "Q = np.random.normal(scale=1./K, size=(n_movies, K))\n",
        "\n",
        "# Step 3: Matrix Factorization via SGD\n",
        "def train_mf(train_data, P, Q, K, steps=100, alpha=0.01, beta=0.01):\n",
        "    Q = Q.T\n",
        "    for step in range(steps):\n",
        "        total_error = 0\n",
        "        for i, j, r in train_data:\n",
        "            prediction = np.dot(P[i], Q[:, j])\n",
        "            error = r - prediction\n",
        "            total_error += error**2\n",
        "\n",
        "            P[i] += alpha * (error * Q[:, j] - beta * P[i])\n",
        "            Q[:, j] += alpha * (error * P[i] - beta * Q[:, j])\n",
        "\n",
        "    return P, Q.T\n",
        "\n",
        "# Train model\n",
        "P_trained, Q_trained = train_mf(train_data, P, Q, K)\n",
        "\n",
        "#  Build full prediction matrix\n",
        "predicted_ratings = np.dot(P_trained, Q_trained.T)\n",
        "\n",
        "#  Evaluate on test set\n",
        "true = []\n",
        "pred = []\n",
        "\n",
        "for i, j, r in test_data:\n",
        "    true.append(r)\n",
        "    pred.append(predicted_ratings[i, j])\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(true, pred))\n",
        "\n",
        "mae = mean_absolute_error(true, pred)\n",
        "\n",
        "print(\"\\n Evaluation Metrics on Test Set:\")\n",
        "print(f\"mean_squared_error: {rmse:.4f}\")\n",
        "print(f\" mean_absolute_error : {mae:.4f}\")\n",
        "\n",
        "# Recommend top N movies to a user\n",
        "def recommend_top_n(user_id, N=5):\n",
        "    user_index = df[df['userId'] == user_id].iloc[0]['user_index']\n",
        "    user_ratings = predicted_ratings[int(user_index)]\n",
        "\n",
        "    # Mask already rated movies\n",
        "    rated_movies = train_df[train_df['user_index'] == user_index]['movie_index'].values\n",
        "    user_ratings[rated_movies] = -np.inf  # ignore seen\n",
        "\n",
        "    # Top N recommendations\n",
        "    top_indices = np.argsort(user_ratings)[-N:][::-1]\n",
        "    movie_ids = [movie_id_map[i] for i in top_indices]\n",
        "\n",
        "    # Load movie titles\n",
        "    movie_info_url = \"https://files.grouplens.org/datasets/movielens/ml-100k/u.item\"\n",
        "    movie_info = pd.read_csv(movie_info_url, sep='|', encoding='latin-1', header=None, usecols=[0, 1], names=['movieId', 'title'])\n",
        "\n",
        "    top_movies = movie_info[movie_info['movieId'].isin(movie_ids)]\n",
        "    print(f\"\\nTop {N} movie recommendations for user {user_id}:\\n\")\n",
        "    print(top_movies)\n",
        "\n",
        "# Recommend for user\n",
        "recommend_top_n(user_id=10, N=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPRDMD82E20B",
        "outputId": "1d9c5cfe-4719-4ee7-f0ef-9b5da32c75ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation Metrics on Test Set:\n",
            "mean_squared_error: 1.0276\n",
            " mean_absolute_error : 0.7887\n",
            "\n",
            "Top 5 movie recommendations for user 10:\n",
            "\n",
            "      movieId                                              title\n",
            "126       127                              Godfather, The (1972)\n",
            "317       318                            Schindler's List (1993)\n",
            "319       320  Paradise Lost: The Child Murders at Robin Hood...\n",
            "1168     1169                                       Fresh (1994)\n",
            "1448     1449                             Pather Panchali (1955)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DvKjL114FDM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}